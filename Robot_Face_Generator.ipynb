{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d271686-ce8e-45cf-93d0-f2fffc8c25c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Robot Face Generator Tool # \n",
    "Written by: Jasper Bosschart\n",
    "## Context ##\n",
    "\n",
    "This is a tool that can generate robot faces using Image Generation Artificial intelligence (AI). <br>\n",
    "The tool is built around the HuggingFaceðŸ¤— [Diffusers](https://huggingface.co/docs/diffusers/index) library. This library can be used to access a wide variety of diffusion AI models available on the HuggingFaceðŸ¤— [website](https://huggingface.co/). This tool uses an Image Generation Model called [\"stable-diffusion-v1-5\"](https://huggingface.co/runwayml/stable-diffusion-v1-5) by runwayml. <br>\n",
    "The tool is still a work in progress and is subjected to change. It is currently built within Jupyter Notebook using Python, as this allows the file to be ran off a remote location easily. This is necessary as the tool requires large amounts of computational power, something a simple laptop is not able to output. Future development might enable for a standalone application.\n",
    "\n",
    "## How does it work? ##\n",
    "A diffusion Model works as follows: \n",
    "It starts out with an image completely filled with Gaussian noise, static basically, what you would see on very old TV's. From this initial (static) image, a diffusion model starts de-noising the image. This process gets repeated many times over until a \"new\" image starts to form. The noise reduction patterns that a diffusion model uses to de-noise an image are related to a text prompt that you give it at the start. But how does it know how a pattern and a text prompt are related?\n",
    "This is done through training, A diffusion model is first trained on a large data set of labeled images. these labeled images gradually get more noisy over time and the diffusion model is tasked to remove the noise each time. As such it learns how to de-noise images and it can link these de-noising patterns it starts to develop to the labels that the images have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c7d30-0b7b-499c-a8e3-7fe7d8cc7b0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How To Generate? ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a10abd-c587-44f4-bd34-1cfa2c787c71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: ###\n",
    "\n",
    "Jupyter Notebook is basically a looking python file, where you can add fully formatted text around and in between snippets of code. It might look quite confusing and a little scary at first, but donâ€™t worry you will be guided through the whole process as long as you keep reading the accompanied text for each code snippet. As mentioned, before we will use a library called diffusers to be able to install our image generation AI. for this diffusers library and our AI to work well, we need some other Libraries too. to download all the necessary  libraries for the tool to work, run the code snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d5b4b-9d84-4536-be25-2acbaed980aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install xformers\n",
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install -U diffusers \n",
    "!pip install -U accelerate \n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff20f1-3d68-4d9a-9827-d17883885882",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: ###\n",
    "Now that we have downloaded the necessary libraries for the tool we need to import them into our current session, something which is not done automatically: <br>\n",
    "Some more code is added to this snippet to be able to create a grid of images later on in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8ea24-12b1-41b8-aef4-39247fca0650",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import accelerate \n",
    "import transformers\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "from PIL import Image\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89a668-b880-465a-b638-0b4b9889bcde",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: ####\n",
    "Now it is time to download the Image Generation Model, This can take some time so don't worry if it does not immediately finish. As you can see in the code snippet above, we specifically imported *StableDiffusionPipeline* from *diffusers*. This function basically does most of the hard work for us, it generates an initial noise image, it creates time intervals for multiple iterations and so forth. <br>\n",
    "to make sure the model runs on a graphics card *.to(\"cuda\")* is added, without that the generation of an image will take 30 minutes instead of 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990563f5-4f25-4086-a9f9-b9472af2b273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#orch.backends.cuda.matmul.allow_tf32 = False\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "#pipe.enable_sequential_cpu_offload()\n",
    "#generator = torch.Generator(\"cuda\").manual_seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe02d7-d7e1-4c60-94ab-b1e8a0bed1c2",
   "metadata": {},
   "source": [
    "### Step 4: ####\n",
    "In this step it is time to let your creativity roam free, you need to create a text prompt of something you want to have generated. As you can see there are two prompts to fill in, a normal *prompt* and a *neg_prompt* or negative prompt. The normal prompt allows you to write whatever you want from the diffusion model, while the negative prompt allows you to write whatever you don't want. \n",
    "\n",
    "You want an image of a boat, but no people on the boat? <br>\n",
    "prompt=\"photograph of a boat\" <br>\n",
    "neg_prompt=\"people\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec41f5-6b3d-4cac-9385-32b1ca2b241f",
   "metadata": {},
   "source": [
    "Some possible prompts you could use to increase the quality of your images and limit the negative aspects: <br>\n",
    "prompt = \"robot portrait, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, 8k\" <br>\n",
    "neg_prompt = \"human features, ugly, beginner, amateur, painting, drawing, disfigured, uncanny valley\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90881c-8ef1-41e0-ba66-881cce1aa65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"robot portrait, realistic\"\n",
    "neg_prompt = \"painting\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f44284-0082-4ce3-9f3d-38d3ccaec8b6",
   "metadata": {},
   "source": [
    "### Step 5: ####\n",
    "You are almost there, you just need to run the following code snippet and wait for approximately 30 seconds, don't sweat it if it take a little longer, the server might be busy. \n",
    "the code snippet currently creates 2 images, computational limitation, using the same text prompts from step 4 and runs it through the pipeline. Afterwards they get saved within *images* and by using *grid* you are displaying them.\n",
    "\n",
    "If the generation takes longer then 5 min, maybe ask for help, you might be running your program without a graphics card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22ab2f-f5e4-4058-b2b9-2fa312b501cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = 2\n",
    "Multi_prompt = [prompt] * num_images\n",
    "Multi_prompt_N = [neg_prompt] * num_images\n",
    "\n",
    "images = pipe(prompt=Multi_prompt, negative_prompt=Multi_prompt_N).images\n",
    "\n",
    "grid = image_grid(images, rows=1, cols=2)\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3c48f-8d90-43ff-a0b3-de375b8f2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = image_grid(images, rows=1, cols=2)\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d6c63-2eb9-4d78-9bef-378f8db1ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.save(f\"robot1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464d049-346c-4865-bd65-c6ab14533bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pipe(prompt=prompt, negative_prompt=neg_prompt, num_images_per_prompt=2).images\n",
    "\n",
    "grid = image_grid(images, rows=1, cols=4)\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c9461-8781-4119-a532-f4edcef7a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ef286-794b-4de0-95fa-f8833c1aa929",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(images[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d8925-1402-4928-a6fc-bcc3aed3495c",
   "metadata": {},
   "source": [
    "## Sources ##\n",
    "For this project the following sources have been used:\n",
    "-  https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work,\n",
    "-  https://huggingface.co/runwayml/stable-diffusion-v1-5,\n",
    "-  https://huggingface.co/docs/diffusers/using-diffusers/write_own_pipeline,\n",
    "-  https://huggingface.co/docs/diffusers/v0.16.0/en/optimization/fp16\n",
    "\n",
    "@InProceedings{Rombach_2022_CVPR, <br>\n",
    "    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\\\"orn}, <br>\n",
    "    title     = {High-Resolution Image Synthesis With Latent Diffusion Models}, <br>\n",
    "    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, <br>\n",
    "    month     = {June}, <br>\n",
    "    year      = {2022}, <br>\n",
    "    pages     = {10684-10695} <br>\n",
    "} <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e8b0d-90ef-4e53-ab25-0baa6085d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84bca5-e51d-473b-b36f-6d70cf3e2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fdec7b1-da83-4d66-a29c-984c305917d3",
   "metadata": {},
   "source": [
    "~/.local/lib/python3.8/site-packages$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ba444-8351-4e00-bf6a-4577f51c8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/.local/lib/python3.8/site-packages$\n",
    "rm -rf workspaces/\n",
    "mkdir workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e3d90-1e51-407b-aec0-d5746925c965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
